Hereâ€™s a clean, professional **README.md** file version of your project description, formatted for GitHub (with Markdown best practices, proper structure, and emoji headers).

---

```markdown
# ğŸ§® Human-in-the-Loop: The Math Routing Agent

**An intelligent "Math Professor" built with Agentic RAG + Human Feedback.**  
This full-stack AI application uses a modern Agentic-RAG pipeline to answer mathematical questions, fallback to web search for unknown queries, and improve continuously using DSPy-powered Human-in-the-Loop (HITL) learning.

---


---

## âœ¨ Core Features

### 1. ğŸ§  Intelligent RAG Routing
- The agent first checks a **Qdrant Cloud VectorDB** for a similar math problem.  
- If a **high-confidence match** is found, it uses that context to answer (source: `knowledge_base`).

### 2. ğŸŒ MCP Web Search Fallback
- If the question isnâ€™t in the knowledge base (e.g., arithmetic, new word problem),  
  the agent automatically performs a **web search using Tavily** (source: `web_search`).

### 3. ğŸ§© AI Gateway (Guardrails)
- **Input Guardrail:** An LLM-based filter that rejects non-math or off-topic questions.  
- **Output Guardrail:** A Python-based check that ensures the AI never replies with a refusal like â€œI canâ€™t answer that.â€

### 4. ğŸ” DSPy-Powered Human-in-the-Loop (HITL)
- Users can rate each answer: **ğŸ‘ Good** or **ğŸ‘ Bad**.  
- All feedback is logged to `feedback_log.jsonl`.  
- If feedback is â€œBad,â€ the backend uses a **DSPy RefinementModule** to re-generate a better answer (source: `refined`).

### 5. ğŸ§¬ Automated Self-Learning
- The `/run-optimization` endpoint uses **DSPyâ€™s BootstrapFewShot optimizer** to read feedback logs and fine-tune prompts.  
- Optimized parameters are saved to `optimized_refiner_module.json` and reloaded on server restart â€” completing the self-learning loop.

---

## ğŸ—ï¸ Architecture Overview

This project uses a **modular, stateless API architecture** with clean separation of concerns.

### ğŸ”¹ Frontend (Vercel)
- Built with **React.js**
- â€œDumbâ€ client that sends and receives JSON via the API

### ğŸ”¹ Backend (Hugging Face Spaces)
- **FastAPI** server with two main endpoints:
  - `POST /ask` â†’ Runs full RAG + Web Search pipeline  
  - `POST /feedback` â†’ Logs feedback and optionally runs DSPy refinement

### ğŸ”¹ External Services
| Component | Service | Purpose |
|------------|----------|----------|
| Vector DB | **Qdrant Cloud** | RAG Knowledge Base |
| Web Search | **Tavily (MCP)** | Fallback search for unknown math questions |
| LLM | **Google Gemini** | Core reasoning, guardrails, and refinement |
| Embeddings | **sentence-transformers** | Vectorizing queries & documents |
| HITL | **DSPy** | Feedback-driven refinement and optimization |

---

## ğŸ› ï¸ Tech Stack

| Category | Technology | Purpose |
|-----------|-------------|----------|
| Backend | FastAPI, Uvicorn | High-performance API server |
| Frontend | React.js | Modern, responsive UI |
| AI Orchestration | DSPy | HITL refinement & optimization |
| Vector DB | Qdrant Cloud | RAG data storage |
| Web Search | Tavily | External search fallback |
| Embeddings | sentence-transformers | Semantic search |
| Deployment | Hugging Face Spaces, Vercel | Hosting backend & frontend |

---

## ğŸ§° Prerequisites

Ensure you have the following installed:
- Python **3.11+**
- Node.js **18+**
- Git

Create a `.env` file (see `.env.example`) with:
```

GOOGLE_API_KEY=
QDRANT_API_KEY=
VECTORDB_URL=
TAVILY_API_KEY=

````

---

## ğŸ§© Setup Instructions

### Step 1: Ingest Data (One-Time Setup)
Populate your **Qdrant database** before running the app.

```bash
# Clone the repository
git clone https://github.com/abhikamui/Math-Rag-Agent.git
cd YOUR_REPO

# Install backend dependencies
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run the ingestion script (reads .env automatically)
python ../scripts/ingest_math_dataset.py
````

---

### Step 2: Run the Backend

```bash
# Inside the /backend folder (with venv active)
uvicorn app.main:app --reload
```

Your backend should now be running on **[http://localhost:8000](http://localhost:8000)**

---

### Step 3: Run the Frontend

```bash
# Open a new terminal
cd ../frontend

# Install dependencies
npm install

# Start the React app
npm start
```

The frontend will open automatically at **[http://localhost:3000](http://localhost:3000)**

---

## ğŸš€ Deployment

### Backend (Hugging Face Spaces)

* Uses `backend/Dockerfile` for container build
* Deploy on **CPU Basic Space (16GB RAM)** for embeddings & models
* Add API keys as **Secrets** in Hugging Face Space settings
* `HF_HOME` and `DISKCACHE_DIR` set in Dockerfile to prevent permission issues

### Frontend (Vercel)

* Deploy `/frontend` as a static site
* Set environment variables:

  * `REACT_APP_API_URL` â†’ Your Hugging Face backend URL
  * `FRONTEND_URL` â†’ Your Vercel frontend URL (for CORS)

---

## ğŸ§‘â€ğŸ« Example Flow

1. User asks a math question â†’
   Agent searches **Qdrant** for similar context
2. If no match â†’ performs **web search via Tavily**
3. Generates answer via **Gemini**
4. User rates response â†’ stored in `feedback_log.jsonl`
5. Poor ratings trigger **DSPy refinement**
6. Optimizer learns from feedback â†’ improves prompts automatically

---

## ğŸ§© Folder Structure

```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ pipelines/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest_math_dataset.py
â”‚
â”œâ”€â”€ feedback_log.jsonl
â”œâ”€â”€ optimized_refiner_module.json
â””â”€â”€ README.md
```

---

## ğŸ§  Future Improvements

* Add **step-by-step math reasoning visualization**
* Implement **multi-turn conversation memory**
* Extend support for **physics and statistics problems**
* Add **auto-refresh dashboard** for feedback analysis

---

## ğŸ“œ License

This project is released under the **MIT License** â€” free for personal and educational use.

---

## ğŸ‘¨â€ğŸ’» Author

Built with â¤ï¸ by **[Kamuni Abhilash]**
ğŸ“§ Contact: abhilashkamuni60@gmail.com
ğŸŒ GitHub: https://github.com/abhikamuni

---
